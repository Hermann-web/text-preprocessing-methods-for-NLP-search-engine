{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "search_engine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7T70rptNAZZ"
      },
      "source": [
        "##Prerequistes\n",
        "*   Python >=3.7\n",
        "*   NLTK\n",
        "*   Scikit-learn\n",
        "*   Pandas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jpw-Vq31sH4"
      },
      "source": [
        "# **1: Créer les keywords à partir d'une phrase en se basant sur les mots d'un dictionnaire et un corpus de texte en passant par la tokenization, la correction, la lemmatization et le removeStopWords**\n",
        "---\n",
        "`fonction: SENTENCE_TO_CORRECT_WORDS`\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNdDV6t8KlUl",
        "outputId": "37004fd4-95e4-4930-9bce-acbfd84aa628"
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import unicodedata, re, string\n",
        "import json \n",
        "\n",
        "\n",
        "def get_dico():\n",
        "    textdir = \"liste.de.mots.francais.frgut_.txt\"\n",
        "    try:DICO = open(textdir,'r',encoding=\"utf-8\").read()\n",
        "    except: DICO = open(textdir,'r').read()\n",
        "\n",
        "    textdir = 'corpus_.txt'\n",
        "    try:CORPUS = open(textdir,'r',encoding=\"utf-8\").read();found=True\n",
        "    except:pass\n",
        "    try: CORPUS = open(textdir,'r').read();found=True \n",
        "    except: pass\n",
        "    CORPUS = open(textdir,'r',encoding='cp1252').read();found=True \n",
        "\n",
        "    \n",
        "    \n",
        "    #WORDS = Counter(words( 'manger bouger difference update All edits that are one edit away from `word`. The subset of `words` that appear in the dictionary of WORDS '))\n",
        "    \n",
        "    #return DICO+CORPUS\n",
        "    return DICO\n",
        "\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    '''\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "    return only_ascii\n",
        "    '''\n",
        "    \"\"\"This method removes all diacritic marks from the given string\"\"\"\n",
        "    norm_txt = unicodedata.normalize('NFD', input_str)\n",
        "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
        "    return unicodedata.normalize('NFC', shaved)\n",
        "\n",
        "def clean_sentence(texte):\n",
        "    # Replace diacritics\n",
        "    texte = remove_accents(texte)\n",
        "    # Lowercase the document\n",
        "    texte = texte.lower()\n",
        "    # Remove Mentions\n",
        "    texte = re.sub(r'@\\w+', '', texte)\n",
        "    # Remove punctuations\n",
        "    texte = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', texte)\n",
        "    # Remove the doubled space\n",
        "    texte = re.sub(r'\\s{2,}', ' ', texte)\n",
        "    #remove whitespaces at the beginning and the end\n",
        "    texte = texte.strip()\n",
        "    \n",
        "    return texte\n",
        "\n",
        "'''\n",
        "#pas cool car il ya des nombres importants\n",
        "def tokenize_sentence3(texte):\n",
        "    #retourner les groupes d'alphabets\n",
        "    return re.findall(r'\\w+', texte.lower())\n",
        "'''\n",
        "'''\n",
        "#inutile ici car sa VA est qu'ik decoupe en phrases\n",
        "def tokenize_sentence2(texte):\n",
        "        #clean the sentence\n",
        "    blob_object = TextBlob(texte)\n",
        "        #tokenize\n",
        "    liste_words = blob_object.words\n",
        "        #return \n",
        "    return liste_words\n",
        "'''\n",
        "def tokenize_sentence(texte):\n",
        "        #clean the sentence \n",
        "    texte = clean_sentence(texte)\n",
        "        #tokenize \n",
        "    liste_words = texte.split()\n",
        "        #return \n",
        "    return liste_words\n",
        "\n",
        "def strip_apostrophe(liste_words):\n",
        "    get_radical = lambda word: word.split('\\'')[-1]\n",
        "    return list(map(get_radical,liste_words))\n",
        "\n",
        "def pre_process(sentence):\n",
        "    #remove '_' from the sentence \n",
        "    sentence = sentence.replace('_','')\n",
        "    \n",
        "    #get words fro the sentence \n",
        "    liste_words = tokenize_sentence(sentence)\n",
        "    #cut out 1 or 2 letters ones \n",
        "    liste_words = [elt for elt in liste_words if len(elt)>2]\n",
        "    #prendre le radical après l'apostrophe\n",
        "    liste_words = strip_apostrophe(liste_words)\n",
        "    print('\\nsentence to words : ',liste_words)\n",
        "    return liste_words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "    \n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def DICO_ET_CORRECTEUR():\n",
        "    \"cette fonction retourne la liste des mots de dictionnaire\"\n",
        "    DICO = get_dico()\n",
        "    WORDS = Counter(pre_process(DICO)) #Counter prends un str et retourne une sorte de liste enrichie\n",
        "    \"correction des mots \"\n",
        "    N = sum(WORDS.values())\n",
        "    P = lambda word: WORDS[word] / N #\"Probability of `word`.\"\n",
        "    \n",
        "    correction = lambda word: max(candidates(word), key=P) #\"Most probable\n",
        "    return WORDS,correction\n",
        "\n",
        "WORDS,CORRECTION = DICO_ET_CORRECTEUR()\n",
        "\n",
        "\n",
        "##stopwords #//https://www.ranks.nl/stopwords/french\n",
        "with open('stp_words_.txt','r') as f:\n",
        "    STOPWORDS = f.read()\n",
        "\n",
        "##bdd de stemmer\n",
        "with open(\"sample_.json\",'r',encoding='cp1252') as json_file:\n",
        "    #json_file.seek(0)\n",
        "    LISTE = json.load(json_file)\n",
        "my_stemmer = lambda word: LISTE[word] if word in LISTE else word\n",
        "\n",
        "def SENTENCE_TO_CORRECT_WORDS(sentence):\n",
        "    \"cette fonction retourne la liste des mots du user\"\n",
        "    print('\\n------------pre_process--------\\n')\n",
        "    liste_words = pre_process(sentence)\n",
        "    print(liste_words)\n",
        "    print('\\n------------correction--------\\n')\n",
        "    liste_words = list(map(CORRECTION,liste_words))\n",
        "    print(liste_words)\n",
        "    print('\\n------------stemming--------\\n')\n",
        "    liste_words = list(map(my_stemmer,liste_words))\n",
        "    print(liste_words)\n",
        "    print('\\n------------remove stop-words--------\\n')\n",
        "    liste_words = [elt for elt in liste_words if elt not in STOPWORDS]\n",
        "    print(liste_words)\n",
        "    print('\\n-------------------------------------\\n')\n",
        "    return liste_words\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_M0vhRqYLAx"
      },
      "source": [
        "# **test**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJFni2QeYJd9",
        "outputId": "37e793bb-8ed4-45b6-acbb-ee4909383940"
      },
      "source": [
        "\n",
        "out = 0 \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('\\n-------------------------------------\\n')\n",
        "    sentence = 'voilà ma phrase'\n",
        "    print('sentence: ',sentence)\n",
        "    liste_words = SENTENCE_TO_CORRECT_WORDS(sentence)\n",
        "    print('liste_words:',liste_words)\n",
        "    print('\\n-------------------------------------\\n')\n",
        "    print('\\ndes phrases à mots raté, d\\'une faute ou deux, à corriger')\n",
        "    while out!=2:\n",
        "        sentence = input('sentence or word: ')\n",
        "        \n",
        "        if sentence: \n",
        "            #CORRECTION(word.lower())\n",
        "            liste_words = SENTENCE_TO_CORRECT_WORDS(sentence)\n",
        "            #print(liste_words)\n",
        "        else: out +=1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------------------\n",
            "\n",
            "sentence:  voilà ma phrase\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['voila', 'phrase']\n",
            "['voila', 'phrase']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['voila', 'phrase']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['voiler', 'phrase']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['voiler', 'phrase']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "liste_words: ['voiler', 'phrase']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "des phrases à mots raté, d'une faute ou deux, à corriger\n",
            "sentence or word: \n",
            "sentence or word: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhyW0rE3miMo",
        "outputId": "023f29b5-cd5b-4ff5-e229-8b4bbdcfe4d3"
      },
      "source": [
        "SENTENCE_TO_CORRECT_WORDS('messaeges d\\'erreues. Le founiseur ARIBA n\\'existeaint pas')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['messaeges', 'erreues', 'founiseur', 'ariba', 'existeaint', 'pas']\n",
            "['messaeges', 'erreues', 'founiseur', 'ariba', 'existeaint', 'pas']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['messages', 'erreurs', 'founisseur', 'ariba', 'existaient', 'pas']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'founisseur', 'ariba', 'exister', 'pas']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'founisseur', 'ariba', 'exister']\n",
            "\n",
            "-------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['message', 'erreur', 'founisseur', 'ariba', 'exister']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RggFlxIzaga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj-3IwHIVcXW"
      },
      "source": [
        "# **1-2: un exemple de lemmatizer**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oj2pUkg30Jai",
        "outputId": "8d259db4-e2e9-4ed3-f0db-92aeb278fe2a"
      },
      "source": [
        "import nltk\n",
        "'''\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nnltk.download('punkt')\\nnltk.download('wordnet')\\nnltk.download('averaged_perceptron_tagger')\\nnltk.download('stopwords')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ayOh2oCtRGn"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import operator\n",
        "import nltk \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "def wordLemmatizer(data,colname):\n",
        "    tag_map = defaultdict(lambda : wn.NOUN)\n",
        "    tag_map['J'] = wn.ADJ\n",
        "    tag_map['V'] = wn.VERB\n",
        "    tag_map['R'] = wn.ADV\n",
        "    file_clean_k =pd.DataFrame()\n",
        "    for index,entry in enumerate(data):\n",
        "        \n",
        "        # Declaring Empty List to store the words that follow the rules for this step\n",
        "        Final_words = []\n",
        "        # Initializing WordNetLemmatizer()\n",
        "        word_Lemmatized = WordNetLemmatizer()\n",
        "        # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "        for word, tag in pos_tag(entry):\n",
        "            # Below condition is to check for Stop words and consider only alphabets\n",
        "            if len(word)>1 and word not in stopwords.words('french') and word.isalpha():\n",
        "                word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "                Final_words.append(word_Final)\n",
        "            # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "                file_clean_k.loc[index,colname] = str(Final_words)\n",
        "                file_clean_k.loc[index,colname] = str(Final_words)\n",
        "                file_clean_k=file_clean_k.replace(to_replace =\"\\[.\", value = '', regex = True)\n",
        "                file_clean_k=file_clean_k.replace(to_replace =\"'\", value = '', regex = True)\n",
        "                file_clean_k=file_clean_k.replace(to_replace =\" \", value = '', regex = True)\n",
        "                file_clean_k=file_clean_k.replace(to_replace ='\\]', value = '', regex = True)\n",
        "\n",
        "    return file_clean_k\n",
        "\n",
        "\n",
        "def wordLemmatizer_(sentence):\n",
        "    #prendre une phrase que retourner un str (les mots sont separes par des ,)\n",
        "    preprocessed_query = preprocessed_query = re.sub(\"\\W+\", \" \", sentence).strip()\n",
        "    tokens = word_tokenize(str(preprocessed_query))\n",
        "    q_df = pd.DataFrame(columns=['q_clean'])\n",
        "    idx = 0\n",
        "    colname = 'keyword_final'\n",
        "    q_df.loc[idx,'q_clean'] =tokens\n",
        "    print('\\n\\n---inputtoken');print(q_df.q_clean)\n",
        "    print('\\n\\n---outputlemma');print(wordLemmatizer(q_df.q_clean,colname).loc[idx,colname])\n",
        "    return wordLemmatizer(q_df.q_clean,colname).loc[idx,colname]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFMWfbMSSUvl"
      },
      "source": [
        "# **2: trouver la meilleure phrase dans une liste de phrase**\n",
        "---\n",
        "`fonction: cosine_similarity_T`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT7a9c3pss34"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import operator\n",
        "import numpy as np \n",
        "import time\n",
        "\n",
        "\n",
        "def init(df_news):\n",
        "  print('init!!!')\n",
        "  ## Create Vocabulary\n",
        "  vocabulary = set()\n",
        "  for doc in df_news.Clean_Keyword:\n",
        "      vocabulary.update(doc.split(','))\n",
        "  vocabulary = list(vocabulary)# Intializating the tfIdf model\n",
        "  tfidf = TfidfVectorizer(vocabulary=vocabulary)# Fit the TfIdf model\n",
        "  tfidf.fit(df_news.Clean_Keyword)# Transform the TfIdf model\n",
        "  tfidf_tran=tfidf.transform(df_news.Clean_Keyword)\n",
        "  globals()['vocabulary'],globals()['tfidf'],globals()['tfidf_tran'] = vocabulary,tfidf,tfidf_tran\n",
        "\n",
        "def gen_vector_T(tokens,df_news,vocabulary,tfidf,tfidf_tran):\n",
        "  Q = np.zeros((len(vocabulary)))    \n",
        "  x= tfidf.transform(tokens)\n",
        "  #print(tokens[0].split(','))\n",
        "  #print(keywords)\n",
        "  for token in tokens[0].split(','):\n",
        "      \n",
        "      try:\n",
        "          ind = vocabulary.index(token)\n",
        "          Q[ind]  = x[0, tfidf.vocabulary_[token]]\n",
        "          print(token,':',ind)\n",
        "      except:\n",
        "          print(token,':','not found')\n",
        "          pass\n",
        "  return Q\n",
        "def cosine_sim(a, b):\n",
        "    if not np.linalg.norm(a) and not np.linalg.norm(b): return -3\n",
        "    if not np.linalg.norm(a):return -1\n",
        "    if not np.linalg.norm(b):return -2\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim   \n",
        "def cosine_similarity_T(k, query,df_news,vocabulary=None,tfidf=None,tfidf_tran=None,mine=True):\n",
        "    try:\n",
        "      vocabulary = globals()['vocabulary']\n",
        "      tfidf = globals()['tfidf']\n",
        "      tfidf_tran = globals()['tfidf_tran']\n",
        "    except:\n",
        "      print('up exception')\n",
        "      init(df_news)\n",
        "    q_df = pd.DataFrame(columns=['q_clean'])\n",
        "    if mine:q_df.loc[0,'q_clean'] =','.join(SENTENCE_TO_CORRECT_WORDS(query))\n",
        "    else:q_df.loc[0,'q_clean'] = wordLemmatizer_(query)\n",
        "    \n",
        "    \n",
        "    print('\\n\\n---q_df');print(q_df)\n",
        "    \n",
        "    print('\\n\\n')\n",
        "    d_cosines = []\n",
        "    query_vector = gen_vector_T(q_df['q_clean'],df_news,vocabulary,tfidf,tfidf_tran )\n",
        "    for d in tfidf_tran.A:\n",
        "        d_cosines.append(cosine_sim(query_vector, d ))\n",
        "                    \n",
        "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
        "    #print(\"\")\n",
        "    d_cosines.sort()\n",
        "    a = pd.DataFrame()\n",
        "    for i,index in enumerate(out):\n",
        "        a.loc[i,'index'] = str(index)\n",
        "        a.loc[i,'Subject'] = df_news['Subject'][index]\n",
        "    for j,simScore in enumerate(d_cosines[-k:][::-1]):\n",
        "        a.loc[j,'Score'] = simScore\n",
        "    return a\n",
        "\n",
        "\n",
        "def test(data,sentence,init_=False,mine=True):\n",
        "  if not init_:\n",
        "    deb = time.time();print('\\n\\n###########')\n",
        "    init(df_news)\n",
        "    print('\\n###########temps init: ', time.time()-deb)\n",
        "  deb = time.time();print('\\n\\n###########')\n",
        "  print(cosine_similarity_T(10, sentence,df_news))\n",
        "  print('\\n###########temps methode 1: ', time.time()-deb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOAa9p_R6xh"
      },
      "source": [
        "# **Example1:**\n",
        "---\n",
        "`BDD: df_news`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uncpXTX0oWq7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_bD21rYsTf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b52e12-8c93-44f4-acab-513083f48aa6"
      },
      "source": [
        "import pandas as pd \n",
        "import re \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "news = pd.read_json('https://raw.githubusercontent.com/zayedrais/DocumentSearchEngine/master/data/newsgroups.json')\n",
        "\n",
        "\n",
        "\n",
        "for i,txt in enumerate(news['content']):\n",
        "    subject = re.findall('Subject:(.*\\n)',txt)\n",
        "    if (len(subject) !=0):\n",
        "        news.loc[i,'Subject'] =str(i)+' '+subject[0]\n",
        "    else:\n",
        "        news.loc[i,'Subject'] ='NA'\n",
        "df_news =news[['Subject','content']]\n",
        "\n",
        "\n",
        "\n",
        "df_news.content =df_news.content.replace(to_replace='from:(.*\\n)',value='',regex=True) ##remove from to email \n",
        "df_news.content =df_news.content.replace(to_replace='lines:(.*\\n)',value='',regex=True)\n",
        "df_news.content =df_news.content.replace(to_replace='[!\"#$%&\\'()*+,/:;<=>?@[\\\\]^_`{|}~]',value=' ',regex=True) #remove punctuation except\n",
        "df_news.content =df_news.content.replace(to_replace='-',value=' ',regex=True)\n",
        "df_news.content =df_news.content.replace(to_replace='\\s+',value=' ',regex=True)    #remove new line\n",
        "df_news.content =df_news.content.replace(to_replace='  ',value='',regex=True)                #remove double white space\n",
        "df_news.content =df_news.content.apply(lambda x:x.strip())  # Ltrim and Rtrim of whitespace\n",
        "\n",
        "\n",
        "\n",
        "df_news['content']=[entry.lower() for entry in df_news['content']]\n",
        "df_news['Word tokenize']= [word_tokenize(entry) for entry in df_news.content]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63c5WgzgtRB5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIZIjS6ky8X1"
      },
      "source": [
        "# **Example1: plus rapide**\n",
        "---\n",
        "`BDD: df_news`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "rQEkNTG2y_wC",
        "outputId": "762c5a2a-23dd-4569-f271-f678c38b9dd8"
      },
      "source": [
        "import pandas as pd \n",
        "df_news = pd.read_json('https://raw.githubusercontent.com/zayedrais/DocumentSearchEngine/master/data/WordLemmatize20NewsGroup.json')\n",
        "df_news.head()\n",
        "df_news.info()\n",
        "df_news.loc[0,'Clean_Keyword']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11314 entries, 0 to 11313\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   Subject        11314 non-null  object\n",
            " 1   Clean_Keyword  11314 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 265.2+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thing,car,nntp,post,host,university,maryland,college,park,line,wonder,anyone,could,enlighten,car,saw,day,sport,car,look,late,early,call,bricklin,door,really,small,addition,front,bumper,separate,rest,body,know,anyone,tellme,model,name,engine,spec,year,production,car,make,history,whatever,info,funky,look,car,please,mail,il,bring,neighborhood,lerxst'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_0jJ7wdSHgb"
      },
      "source": [
        "# **Text example1**\n",
        "---\n",
        "`output: mesures de similarités`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in_yInEsA0gN",
        "outputId": "379b8bb5-bef9-44c8-a23d-aadd7ef32d3e"
      },
      "source": [
        "init"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.init>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB55Q3gQp2JP",
        "outputId": "cc245f2d-eec8-4af1-e99d-54c728dd241f"
      },
      "source": [
        "sentence = \"computer science\"\n",
        "test(df_news,sentence,init_=False,mine=True) #il v bugger sur l'anglais à moins que je remplace les data (stop_words et corpus et tout)\n",
        "sentence = \"state diagrams\"\n",
        "test(df_news,sentence,init_=True,mine=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "###########\n",
            "init!!!\n",
            "\n",
            "###########temps init:  3.1772680282592773\n",
            "\n",
            "\n",
            "###########\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['computer', 'science']\n",
            "['computer', 'science']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['computer', 'science']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['computer', 'science']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['computer', 'science']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "---q_df\n",
            "            q_clean\n",
            "0  computer,science\n",
            "\n",
            "\n",
            "\n",
            "computer : 39988\n",
            "science : 7641\n",
            "   index                                            Subject     Score\n",
            "0   2231             2231 Computer Engr vs Computer Science  0.396137\n",
            "1  10340                      10340 Science and Methodology  0.302603\n",
            "2   4173                   4173 Rawlins debunks creationism  0.284936\n",
            "3   4326             4326 Computer Engr vs Computer Science  0.284256\n",
            "4   6921            6921 Automatic layout of state diagrams  0.260732\n",
            "5   7618  7618 Solution Why do I need xrdb m when Xdefau...  0.251170\n",
            "6   5741                   5741 Rawlins debunks creationism  0.247442\n",
            "7   8464                                 8464 Date is stuck  0.238985\n",
            "8   3177    3177 Homeopathy a respectable medical tradition  0.235738\n",
            "9   4366             4366 Computer Engr vs Computer Science  0.227186\n",
            "\n",
            "###########temps methode 1:  10.28007435798645\n",
            "\n",
            "\n",
            "###########\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['state', 'diagrams']\n",
            "['state', 'diagrams']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['tate', 'diagramme']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['tater', 'diagramme']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['tater', 'diagramme']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "---q_df\n",
            "           q_clean\n",
            "0  tater,diagramme\n",
            "\n",
            "\n",
            "\n",
            "tater : 35726\n",
            "diagramme : not found\n",
            "  index                                            Subject     Score\n",
            "0  6375                           6375 Early BBDDD Returns  0.170922\n",
            "1  3711                           3711 Early BBDDD Returns  0.165878\n",
            "2  3982   3982 Binaca Blast Deep Drive Derby BBDDD Returns  0.075045\n",
            "3  3775                         3775 Analog switches Balan  0.000000\n",
            "4  3774          3774 A question that has bee bothering me  0.000000\n",
            "5  3773  3773 After 2000 years can we say that Christia...  0.000000\n",
            "6  3772                   3772 CR ROM Drive Recommendation  0.000000\n",
            "7  3771                                  3771 Windows Help  0.000000\n",
            "8  3770       3770 AF ATS Red Army Fraction RAF communique  0.000000\n",
            "9  3769            3769 With a surge in the last two weeks  0.000000\n",
            "\n",
            "###########temps methode 1:  3.9334299564361572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58v4G7RBB1x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvXkfg1QBuI-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8LwLhYSoQj"
      },
      "source": [
        "# **Example2:**\n",
        "---\n",
        "`BDD: df_new`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7zq_zxQTl0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9812d66f-d384-4a88-d0c9-4c14cd9d8d75"
      },
      "source": [
        "def open_file(textdir):\n",
        "  found = False\n",
        "  try:texte = open(textdir,'r',encoding=\"utf-8\").read();found=True\n",
        "  except:pass\n",
        "  try: texte = open(textdir,'r').read();found=True \n",
        "  except: pass\n",
        "  if not found:\n",
        "    texte = open(textdir,'r',encoding='cp1252').read();found=True\n",
        "  return  texte\n",
        "def add_col(df_news,titre,keywords):\n",
        "  return df_news.append(dict(zip(df_news.columns,[titre, keywords])), ignore_index=True)\n",
        "SENTENCE_TO_CORRECT_WORDS('La PR reste au statut «\\xa0Approuve(e)\\xa0» et il n’y a pas de commande\\\"\\'')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['reste', 'statut', 'approuve', 'n’y', 'pas', 'commande']\n",
            "['reste', 'statut', 'approuve', 'n’y', 'pas', 'commande']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['reste', 'statut', 'approuve', 'non', 'pas', 'commande']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['rester', 'statut', 'approuver', 'non', 'pas', 'commander']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['rester', 'statut', 'approuver', 'commander']\n",
            "\n",
            "-------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rester', 'statut', 'approuver', 'commander']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEdPkpsks1DW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4bfefb9-85ce-4d28-f936-bffb9758f581"
      },
      "source": [
        "liste_pb = [elt for elt in open_file('liste_pb_.txt').split('\\n') if elt]\n",
        "df_new = df_news.drop(df_news.index)\n",
        "for i,titre in enumerate(liste_pb):\n",
        "  keywords = ','.join(SENTENCE_TO_CORRECT_WORDS(titre))\n",
        "  df_new = add_col(df_new,titre,keywords)\n",
        "df_new.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'fournisseur', 'ariba', 'existe', 'pas']\n",
            "['message', 'erreur', 'fournisseur', 'ariba', 'existe', 'pas']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'aria', 'existe', 'pas']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'aria', 'exister', 'pas']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'aria', 'exister']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'commande', 'd’article', 'non', 'autorise', 'otp']\n",
            "['message', 'erreur', 'commande', 'd’article', 'non', 'autorise', 'otp']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'commande', 'article', 'non', 'autorise', 'oto']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'commander', 'article', 'non', 'autoriser', 'oto']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'commander', 'article', 'autoriser', 'oto']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'statut', 'utilisateur', 'ferm', 'actif', 'otp']\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'ferm', 'actif', 'otp']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'fer', 'actif', 'oto']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'fer', 'actif', 'oto']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'actif', 'oto']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'statut', 'systeme', 'tclo', 'actif', 'ord']\n",
            "['message', 'erreur', 'statut', 'systeme', 'tclo', 'actif', 'ord']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'systeme', 'col', 'actif', 'nord']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'systeme', 'col', 'actif', 'nord']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'systeme', 'col', 'actif', 'nord']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'cost', 'center', 'change', 'could', 'not', 'effected']\n",
            "['message', 'erreur', 'cost', 'center', 'change', 'could', 'not', 'effected']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'coat', 'centre', 'change', 'cold', 'non', 'affecte']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'coat', 'centrer', 'changer', 'cold', 'non', 'affecter']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'coat', 'centrer', 'changer', 'cold', 'affecter']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['messaeg', 'erreur', 'otp', 'change', 'could', 'not', 'effected']\n",
            "['messaeg', 'erreur', 'otp', 'change', 'could', 'not', 'effected']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'oto', 'change', 'cold', 'non', 'affecte']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'oto', 'changer', 'cold', 'non', 'affecter']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'oto', 'changer', 'cold', 'affecter']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['messaeg', 'erreur', 'entrez', 'centre', 'couts']\n",
            "['messaeg', 'erreur', 'entrez', 'centre', 'couts']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'entrez', 'centre', 'couts']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'centrer', 'cout']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'centrer', 'cout']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'indiquez', 'une', 'seule', 'imputation', 'non', 'statistique']\n",
            "['message', 'erreur', 'indiquez', 'une', 'seule', 'imputation', 'non', 'statistique']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'indiquez', 'une', 'seule', 'imputation', 'non', 'statistique']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'indiquer', 'un', 'seul', 'imputation', 'non', 'statistique']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'indiquer', 'imputation', 'statistique']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'imputations', 'ont', 'des', 'centres', 'profit', 'differents']\n",
            "['message', 'erreur', 'imputations', 'ont', 'des', 'centres', 'profit', 'differents']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'imputations', 'ont', 'des', 'centres', 'profit', 'differents']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'imputation', 'ont', 'de', 'centrer', 'profit', 'different']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'imputation', 'centrer', 'profit']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'poste', 'ordre', 'depassement', 'budget']\n",
            "['message', 'erreur', 'poste', 'ordre', 'depassement', 'budget']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'poste', 'ordre', 'depassement', 'budget']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'poster', 'ordre', 'depassement', 'budget']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'poster', 'ordre', 'depassement', 'budget']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'entrez', 'une', 'quantite', 'commande']\n",
            "['message', 'erreur', 'entrez', 'une', 'quantite', 'commande']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'entrez', 'une', 'quantite', 'commande']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'un', 'quantite', 'commander']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'quantite', 'commander']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'indiquez', 'quantite']\n",
            "['message', 'erreur', 'indiquez', 'quantite']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'indiquez', 'quantite']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'indiquer', 'quantite']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'indiquer', 'quantite']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'prix', 'net', 'doit', 'etre', 'superieur']\n",
            "['message', 'erreur', 'prix', 'net', 'doit', 'etre', 'superieur']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'prix', 'net', 'doit', 'etre', 'superieur']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'prix', 'net', 'doit', 'etre', 'superieur']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'prix', 'net', 'superieur']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'les', 'conditions', 'paiement', 'sont', 'pas', 'creees']\n",
            "['message', 'erreur', 'les', 'conditions', 'paiement', 'sont', 'pas', 'creees']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'les', 'conditions', 'paiement', 'sont', 'pas', 'creees']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'le', 'condition', 'paiement', 'sont', 'pas', 'creer']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'condition', 'paiement', 'creer']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'centre', 'profit', 'existe', 'pas', 'perimetre', 'comptabilis']\n",
            "['message', 'erreur', 'centre', 'profit', 'existe', 'pas', 'perimetre', 'comptabilis']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'centre', 'profit', 'existe', 'pas', 'perimetre', 'comptabilise']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'centrer', 'profit', 'exister', 'pas', 'perimetre', 'comptabiliser']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'centrer', 'profit', 'exister', 'perimetre', 'comptabiliser']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  []\n",
            "[]\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "[]\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "[]\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "[]\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'utilisateur', 'traite', 'deja', 'cde', 'achat']\n",
            "['message', 'erreur', 'utilisateur', 'traite', 'deja', 'cde', 'achat']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'utilisateur', 'traite', 'deja', 'cede', 'achat']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'utilisateur', 'traiter', 'deja', 'ceder', 'achat']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'utilisateur', 'traiter', 'deja', 'ceder', 'achat']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'validation', 'compte', 'est', 'interdit', 'sur', 'centre']\n",
            "['message', 'erreur', 'validation', 'compte', 'est', 'interdit', 'sur', 'centre']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'validation', 'compte', 'est', 'interdit', 'sur', 'centre']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'validation', 'compter', 'est', 'interdire', 'sur', 'centrer']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'validation', 'compter', 'interdire', 'centrer']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'validation', 'compte', 'doit', 'etre', 'impute', 'sur', 'centre', 'cout']\n",
            "['message', 'erreur', 'validation', 'compte', 'doit', 'etre', 'impute', 'sur', 'centre', 'cout']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'validation', 'compte', 'doit', 'etre', 'impute', 'sur', 'centre', 'cout']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'validation', 'compter', 'doit', 'etre', 'imputer', 'sur', 'centrer', 'cout']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'validation', 'compter', 'imputer', 'centrer', 'cout']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'fournisseur', 'mdm', 'n’existe', 'pas']\n",
            "['message', 'erreur', 'fournisseur', 'mdm', 'n’existe', 'pas']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'meme', 'coexiste', 'pas']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'meme', 'coexister', 'pas']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'coexister']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'fournisseur', 'mdm', 'est', 'bloque', 'pour', 'l’organisation', 'achats']\n",
            "['message', 'erreur', 'fournisseur', 'mdm', 'est', 'bloque', 'pour', 'l’organisation', 'achats']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'meme', 'est', 'bloque', 'pour', 'reorganisation', 'achats']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'meme', 'est', 'bloquer', 'pour', 'reorganisation', 'achat']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'bloquer', 'reorganisation', 'achat']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'date', 'livraison', 'situee', 'dans', 'passe']\n",
            "['message', 'erreur', 'date', 'livraison', 'situee', 'dans', 'passe']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'date', 'livraison', 'situee', 'dans', 'passe']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'dater', 'livraison', 'situer', 'dan', 'passer']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'dater', 'livraison', 'situer', 'passer']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'qte', 'livree', 'est', 'differente', 'qte', 'facturee', 'fonction', 'impossible']\n",
            "['message', 'erreur', 'qte', 'livree', 'est', 'differente', 'qte', 'facturee', 'fonction', 'impossible']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'que', 'livree', 'est', 'differente', 'que', 'facturee', 'fonction', 'impossible']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'que', 'livrer', 'est', 'different', 'que', 'facturer', 'fonction', 'impossible']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'livrer', 'facturer', 'fonction', 'impossible']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'groupe', 'd’acheteurs', 'not', 'non', 'defini', 'verifiez', 'vos', 'donnees']\n",
            "['message', 'erreur', 'groupe', 'd’acheteurs', 'not', 'non', 'defini', 'verifiez', 'vos', 'donnees']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'groupe', 'acheteurs', 'non', 'non', 'defini', 'verifiez', 'vos', 'donnees']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'grouper', 'acheteur', 'non', 'non', 'definir', 'verifier', 'votre', 'donnee']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'grouper', 'acheteur', 'definir', 'verifier', 'donnee']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'founisseur', 'xxxx', 'n’existe', 'pas']\n",
            "['message', 'erreur', 'founisseur', 'xxxx', 'n’existe', 'pas']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'fouisseur', 'xxxx', 'coexiste', 'pas']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'fouisseur', 'xxxx', 'coexister', 'pas']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'fouisseur', 'xxxx', 'coexister']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'cpte', 'general', 'peut', 'etre', 'utilise', 'corrigez']\n",
            "['message', 'erreur', 'cpte', 'general', 'peut', 'etre', 'utilise', 'corrigez']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'cote', 'general', 'peut', 'etre', 'utilise', 'corrigez']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'coter', 'general', 'peut', 'etre', 'utiliser', 'corriger']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'coter', 'general', 'utiliser', 'corriger']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'erreur', 'conversion', 'des', 'quantites', 'lors', 'calcul', 'prix', 'net']\n",
            "['message', 'erreur', 'erreur', 'conversion', 'des', 'quantites', 'lors', 'calcul', 'prix', 'net']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'erreur', 'conversion', 'des', 'quantites', 'lors', 'calcul', 'prix', 'net']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'erreur', 'conversion', 'de', 'quantite', 'lors', 'calcul', 'prix', 'net']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'erreur', 'conversion', 'quantite', 'calcul', 'prix', 'net']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'qte', 'tolerance', 'livr', 'excedentaire', 'inferieur', 'quantite', 'livree']\n",
            "['message', 'erreur', 'qte', 'tolerance', 'livr', 'excedentaire', 'inferieur', 'quantite', 'livree']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'que', 'tolerance', 'livre', 'excedentaire', 'inferieur', 'quantite', 'livree']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'que', 'tolerance', 'livrer', 'excedentaire', 'inferieur', 'quantite', 'livrer']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'tolerance', 'livrer', 'excedentaire', 'inferieur', 'quantite', 'livrer']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'fonctions', 'oblig', 'suivantes', 'non', 'def', 'gestion', 'des', 'partenaires']\n",
            "['message', 'erreur', 'fonctions', 'oblig', 'suivantes', 'non', 'def', 'gestion', 'des', 'partenaires']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'fonctions', 'oblige', 'suivantes', 'non', 'des', 'gestion', 'des', 'partenaires']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'fonction', 'obliger', 'suivant', 'non', 'de', 'gestion', 'de', 'partenaire']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'fonction', 'obliger', 'gestion', 'partenaire']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'article', 'non', 'gere', 'dans', 'division']\n",
            "['message', 'erreur', 'article', 'non', 'gere', 'dans', 'division']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'article', 'non', 'gere', 'dans', 'division']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'article', 'non', 'gerer', 'dan', 'division']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'article', 'gerer', 'division']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'renseigner', 'correctement', 'demandeur']\n",
            "['message', 'erreur', 'renseigner', 'correctement', 'demandeur']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'renseigner', 'correctement', 'demandeur']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'renseigner', 'correctement', 'demandeur']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'renseigner', 'correctement', 'demandeur']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'l’unite', 'quantite', 'par', 'n’est', 'pas', 'definie', 'dans', 'langue']\n",
            "['message', 'erreur', 'l’unite', 'quantite', 'par', 'n’est', 'pas', 'definie', 'dans', 'langue']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'lignite', 'quantite', 'par', 'est', 'pas', 'definie', 'dans', 'langue']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'lignite', 'quantite', 'par', 'est', 'pas', 'definir', 'dan', 'langue']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'lignite', 'quantite', 'definir', 'langue']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['quantite', 'est', 'superieure', 'quantite', 'disponible']\n",
            "['quantite', 'est', 'superieure', 'quantite', 'disponible']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['quantite', 'est', 'superieure', 'quantite', 'disponible']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['quantite', 'est', 'superieur', 'quantite', 'disponible']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['quantite', 'superieur', 'quantite', 'disponible']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'existe', 'des', 'factures', 'pour', 'cas', 'creation', 'mouvement', 'impossible']\n",
            "['message', 'erreur', 'existe', 'des', 'factures', 'pour', 'cas', 'creation', 'mouvement', 'impossible']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'existe', 'des', 'factures', 'pour', 'cas', 'creation', 'mouvement', 'impossible']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'exister', 'de', 'facturer', 'pour', 'cas', 'creation', 'mouvement', 'impossible']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'exister', 'facturer', 'cas', 'creation', 'mouvement', 'impossible']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'qte', 'entre', 'facture', 'pas', 'atteint', 'difference']\n",
            "['message', 'erreur', 'qte', 'entre', 'facture', 'pas', 'atteint', 'difference']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'que', 'entre', 'facture', 'pas', 'atteint', 'difference']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'que', 'entrer', 'facturer', 'pas', 'atteindre', 'difference']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'facturer', 'atteindre', 'difference']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'qte', 'entree', 'march', 'pas', 'atteint', 'difference']\n",
            "['message', 'erreur', 'qte', 'entree', 'march', 'pas', 'atteint', 'difference']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'que', 'entree', 'marche', 'pas', 'atteint', 'difference']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'que', 'entrer', 'marcher', 'pas', 'atteindre', 'difference']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'marcher', 'atteindre', 'difference']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'qte', 'commandee', 'depasse']\n",
            "['message', 'erreur', 'qte', 'commandee', 'depasse']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'que', 'commandee', 'depasse']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'que', 'commander', 'depasser']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'commander', 'depasser']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'ecriture', 'impossible', 'immob', 'mise', 'hors', 'service']\n",
            "['message', 'erreur', 'ecriture', 'impossible', 'immob', 'mise', 'hors', 'service']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'ecriture', 'impossible', 'immole', 'mise', 'hors', 'service']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'ecriture', 'impossible', 'immoler', 'miser', 'hors', 'service']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'ecriture', 'impossible', 'immoler', 'miser', 'service']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'quantite', 'totale', 'est', 'differente', 'celle', 'controlee', 'douan']\n",
            "['message', 'erreur', 'quantite', 'totale', 'est', 'differente', 'celle', 'controlee', 'douan']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'quantite', 'totale', 'est', 'differente', 'celle', 'controlee', 'douant']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'quantite', 'total', 'est', 'different', 'celui', 'controler', 'douant']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'quantite', 'total', 'controler', 'douant']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'date', 'comptable', 'interdite', 'pour', 'saisie', 'receptions']\n",
            "['message', 'erreur', 'date', 'comptable', 'interdite', 'pour', 'saisie', 'receptions']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'date', 'comptable', 'interdite', 'pour', 'saisie', 'receptions']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'dater', 'comptable', 'interdire', 'pour', 'saisir', 'reception']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'dater', 'comptable', 'interdire', 'saisir', 'reception']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'enregistrer', 'uniq', 'les', 'periodes', 'possible', 'dom', 'val']\n",
            "['message', 'erreur', 'enregistrer', 'uniq', 'les', 'periodes', 'possible', 'dom', 'val']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'enregistrer', 'unit', 'les', 'periodes', 'possible', 'dom', 'val']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'enregistrer', 'unir', 'le', 'periode', 'possible', 'dom', 'val']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'enregistrer', 'unir', 'periode', 'possible', 'dom']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'periode', 'n’est', 'pas', 'ouverte', 'pour', 'type', 'dpte']\n",
            "['message', 'erreur', 'periode', 'n’est', 'pas', 'ouverte', 'pour', 'type', 'dpte']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'periode', 'est', 'pas', 'ouverte', 'pour', 'type', 'date']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'periode', 'est', 'pas', 'ouvrir', 'pour', 'typer', 'dater']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'periode', 'ouvrir', 'typer', 'dater']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'document', 'contient', 'aucun', 'poste']\n",
            "['message', 'erreur', 'document', 'contient', 'aucun', 'poste']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'document', 'contient', 'aucun', 'poste']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'document', 'contenir', 'aucun', 'poster']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'document', 'contenir', 'poster']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'aucune', 'entree', 'stock', 'possible', 'pour', 'commande']\n",
            "['message', 'erreur', 'aucune', 'entree', 'stock', 'possible', 'pour', 'commande']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'aucune', 'entree', 'stock', 'possible', 'pour', 'commande']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'aucun', 'entrer', 'stock', 'possible', 'pour', 'commander']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'stock', 'possible', 'commander']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'entree', 'marchandises', 'commande', 'non', 'autorise', 'otp']\n",
            "['message', 'erreur', 'entree', 'marchandises', 'commande', 'non', 'autorise', 'otp']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'entree', 'marchandises', 'commande', 'non', 'autorise', 'oto']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'marchandise', 'commander', 'non', 'autoriser', 'oto']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'entrer', 'marchandise', 'commander', 'autoriser', 'oto']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'centre', 'est', 'bloque', 'aux', 'ecritures', 'couts', 'primaires']\n",
            "['message', 'erreur', 'centre', 'est', 'bloque', 'aux', 'ecritures', 'couts', 'primaires']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'centre', 'est', 'bloque', 'aux', 'ecritures', 'couts', 'primaires']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'centrer', 'est', 'bloquer', 'aux', 'ecriture', 'cout', 'primaire']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'centrer', 'bloquer', 'ecriture', 'cout', 'primaire']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'statut', 'utilisateur', 'zbha', 'actif', 'otp']\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'zbha', 'actif', 'otp']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'bah', 'actif', 'oto']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'bah', 'actif', 'oto']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'actif', 'oto']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'statut', 'systeme', 'bloq', 'actif', 'otp']\n",
            "['message', 'erreur', 'statut', 'systeme', 'bloq', 'actif', 'otp']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'systeme', 'bloc', 'actif', 'oto']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'systeme', 'bloc', 'actif', 'oto']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'systeme', 'bloc', 'actif', 'oto']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'statut', 'utilisateur', 'ferm', 'actif', 'otp']\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'ferm', 'actif', 'otp']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'fer', 'actif', 'oto']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'fer', 'actif', 'oto']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'statut', 'utilisateur', 'actif', 'oto']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'ecritures', 'd’immobilisations', 'pour', 'ste']\n",
            "['message', 'erreur', 'ecritures', 'd’immobilisations', 'pour', 'ste']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'ecritures', 'immobilisations', 'pour', 'ote']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'ecriture', 'immobilisation', 'pour', 'oter']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'ecriture', 'immobilisation', 'oter']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'les', 'donnees', 'division', 'article', 'sont', 'bloquees', 'par', 'utilisateur']\n",
            "['message', 'erreur', 'les', 'donnees', 'division', 'article', 'sont', 'bloquees', 'par', 'utilisateur']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'les', 'donnees', 'division', 'article', 'sont', 'bloquees', 'par', 'utilisateur']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'le', 'donnee', 'division', 'article', 'sont', 'bloquer', 'par', 'utilisateur']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'donnee', 'division', 'article', 'bloquer', 'utilisateur']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'utilisateur', 'yraribatch', 'traite', 'deja', 'poste', 'document', 'achat']\n",
            "['message', 'erreur', 'utilisateur', 'yraribatch', 'traite', 'deja', 'poste', 'document', 'achat']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'utilisateur', 'yraribatch', 'traite', 'deja', 'poste', 'document', 'achat']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'utilisateur', 'yraribatch', 'traiter', 'deja', 'poster', 'document', 'achat']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'utilisateur', 'yraribatch', 'traiter', 'deja', 'poster', 'document', 'achat']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'tableau', 'valeur', 'acquisition', 'devient', 'negative']\n",
            "['message', 'erreur', 'tableau', 'valeur', 'acquisition', 'devient', 'negative']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'tableau', 'valeur', 'acquisition', 'devient', 'negative']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'tableau', 'valeur', 'acquisition', 'devier', 'negatif']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'tableau', 'acquisition', 'devier', 'negatif']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'fournisseur', 'non', 'present', 'dans', 'ariba', 'mais', 'present', 'dans', 'sap']\n",
            "['message', 'erreur', 'fournisseur', 'non', 'present', 'dans', 'ariba', 'mais', 'present', 'dans', 'sap']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'non', 'present', 'dans', 'aria', 'mais', 'present', 'dans', 'sac']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'non', 'present', 'dan', 'aria', 'mais', 'present', 'dan', 'sac']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'fournisseur', 'present', 'aria', 'present']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'vendeur', 'ete', 'supprime', 'modification']\n",
            "['message', 'erreur', 'vendeur', 'ete', 'supprime', 'modification']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'vendeur', 'ete', 'supprime', 'modification']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'vendeur', 'ete', 'supprimer', 'modification']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'vendeur', 'supprimer', 'modification']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['message', 'erreur', 'reste', 'statut', 'approuve', 'n’y', 'pas', 'commande']\n",
            "['message', 'erreur', 'reste', 'statut', 'approuve', 'n’y', 'pas', 'commande']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['message', 'erreur', 'reste', 'statut', 'approuve', 'non', 'pas', 'commande']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['message', 'erreur', 'rester', 'statut', 'approuver', 'non', 'pas', 'commander']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['message', 'erreur', 'rester', 'statut', 'approuver', 'commander']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['ppp']\n",
            "['ppp']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['pop']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['pop']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['pop']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo4', 'commande', 'envoi', 'une', 'commande', 'manuelle']\n",
            "['uo4', 'commande', 'envoi', 'une', 'commande', 'manuelle']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'commande', 'envoi', 'une', 'commande', 'manuelle']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'commander', 'envoi', 'un', 'commander', 'manuel']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['commander', 'envoi', 'commander', 'manuel']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo5', 'reception', 'anomalie', 'workflow']\n",
            "['uo5', 'reception', 'anomalie', 'workflow']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'reception', 'anomalie', 'workflow']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'reception', 'anomalie', 'workflow']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['reception', 'anomalie', 'workflow']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo5', 'reception', 'modification', 'reception']\n",
            "['uo5', 'reception', 'modification', 'reception']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'reception', 'modification', 'reception']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'reception', 'modification', 'reception']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['reception', 'modification', 'reception']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo5', 'reception', 'annulation', 'reception']\n",
            "['uo5', 'reception', 'annulation', 'reception']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'reception', 'annulation', 'reception']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'reception', 'annulation', 'reception']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['reception', 'annulation', 'reception']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo5', 'reception', 'forcer', 'reception']\n",
            "['uo5', 'reception', 'forcer', 'reception']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'reception', 'forcer', 'reception']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'reception', 'forcer', 'reception']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['reception', 'forcer', 'reception']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo3', 'demande', 'achat', 'demande', 'support', 'creation']\n",
            "['uo3', 'demande', 'achat', 'demande', 'support', 'creation']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'demande', 'achat', 'demande', 'support', 'creation']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'demander', 'achat', 'demander', 'support', 'creation']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['demander', 'achat', 'demander', 'support', 'creation']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo3', 'demande', 'achat', 'demande', 'support', 'modification']\n",
            "['uo3', 'demande', 'achat', 'demande', 'support', 'modification']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'demande', 'achat', 'demande', 'support', 'modification']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'demander', 'achat', 'demander', 'support', 'modification']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['demander', 'achat', 'demander', 'support', 'modification']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo3', 'demande', 'achat', 'demande', 'support', 'annulation']\n",
            "['uo3', 'demande', 'achat', 'demande', 'support', 'annulation']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'demande', 'achat', 'demande', 'support', 'annulation']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'demander', 'achat', 'demander', 'support', 'annulation']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['demander', 'achat', 'demander', 'support', 'annulation']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['uo4', 'commande', 'demande', 'support', 'modification', 'commande']\n",
            "['uo4', 'commande', 'demande', 'support', 'modification', 'commande']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['non', 'commande', 'demande', 'support', 'modification', 'commande']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['non', 'commander', 'demander', 'support', 'modification', 'commander']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['commander', 'demander', 'support', 'modification', 'commander']\n",
            "\n",
            "-------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Clean_Keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Message d'erreur : \"Le fournisseur ARIBA n'exi...</td>\n",
              "      <td>message,erreur,fournisseur,aria,exister</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Message d'erreur : \"Commande d’article non aut...</td>\n",
              "      <td>message,erreur,commander,article,autoriser,oto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Message d'erreur : \"Statut utilisateur FERM ac...</td>\n",
              "      <td>message,erreur,statut,utilisateur,actif,oto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Message d'erreur : \"Statut systeme TCLO actif ...</td>\n",
              "      <td>message,erreur,statut,systeme,col,actif,nord</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Message d'erreur \"___ Cost center change could...</td>\n",
              "      <td>message,erreur,coat,centrer,changer,cold,affecter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Messaeg d'erreur \"___ OTP change could not be ...</td>\n",
              "      <td>message,erreur,oto,changer,cold,affecter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Messaeg d'erreur \"Entrez Centre de couts\"</td>\n",
              "      <td>message,erreur,entrer,centrer,cout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Message d'erreur \"Indiquez une seule imputatio...</td>\n",
              "      <td>message,erreur,indiquer,imputation,statistique</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Message d'erreur \"Imputations CO ont des centr...</td>\n",
              "      <td>message,erreur,imputation,centrer,profit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Message d'erreur \"Poste ___ Ordre ___ depassem...</td>\n",
              "      <td>message,erreur,poster,ordre,depassement,budget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Message d'erreur \"Entrez une quantite de comma...</td>\n",
              "      <td>message,erreur,entrer,quantite,commander</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Message d'erreur \"Indiquez la quantite\"</td>\n",
              "      <td>message,erreur,indiquer,quantite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Message d'erreur \"Le prix net doit etre superi...</td>\n",
              "      <td>message,erreur,prix,net,superieur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Message d'erreur \"Les conditions de paiement _...</td>\n",
              "      <td>message,erreur,condition,paiement,creer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Message d'erreur \"Le centre de profit __ n'exi...</td>\n",
              "      <td>message,erreur,centrer,profit,exister,perimetr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>\"</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Message d'erreur \"Utilisateur ___ traite deja ...</td>\n",
              "      <td>message,erreur,utilisateur,traiter,deja,ceder,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Message d'erreur \"validation ___ : le compte _...</td>\n",
              "      <td>message,erreur,validation,compter,interdire,ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Message d'erreur \"Validation ___ : le compte _...</td>\n",
              "      <td>message,erreur,validation,compter,imputer,cent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Message d'erreur \"Le fournisseur MDM___ n’exis...</td>\n",
              "      <td>message,erreur,fournisseur,coexister</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Subject                                      Clean_Keyword\n",
              "0   Message d'erreur : \"Le fournisseur ARIBA n'exi...            message,erreur,fournisseur,aria,exister\n",
              "1   Message d'erreur : \"Commande d’article non aut...     message,erreur,commander,article,autoriser,oto\n",
              "2   Message d'erreur : \"Statut utilisateur FERM ac...        message,erreur,statut,utilisateur,actif,oto\n",
              "3   Message d'erreur : \"Statut systeme TCLO actif ...       message,erreur,statut,systeme,col,actif,nord\n",
              "4   Message d'erreur \"___ Cost center change could...  message,erreur,coat,centrer,changer,cold,affecter\n",
              "5   Messaeg d'erreur \"___ OTP change could not be ...           message,erreur,oto,changer,cold,affecter\n",
              "6           Messaeg d'erreur \"Entrez Centre de couts\"                 message,erreur,entrer,centrer,cout\n",
              "7   Message d'erreur \"Indiquez une seule imputatio...     message,erreur,indiquer,imputation,statistique\n",
              "8   Message d'erreur \"Imputations CO ont des centr...           message,erreur,imputation,centrer,profit\n",
              "9   Message d'erreur \"Poste ___ Ordre ___ depassem...     message,erreur,poster,ordre,depassement,budget\n",
              "10  Message d'erreur \"Entrez une quantite de comma...           message,erreur,entrer,quantite,commander\n",
              "11            Message d'erreur \"Indiquez la quantite\"                   message,erreur,indiquer,quantite\n",
              "12  Message d'erreur \"Le prix net doit etre superi...                  message,erreur,prix,net,superieur\n",
              "13  Message d'erreur \"Les conditions de paiement _...            message,erreur,condition,paiement,creer\n",
              "14  Message d'erreur \"Le centre de profit __ n'exi...  message,erreur,centrer,profit,exister,perimetr...\n",
              "15                                                  \"                                                   \n",
              "16  Message d'erreur \"Utilisateur ___ traite deja ...  message,erreur,utilisateur,traiter,deja,ceder,...\n",
              "17  Message d'erreur \"validation ___ : le compte _...  message,erreur,validation,compter,interdire,ce...\n",
              "18  Message d'erreur \"Validation ___ : le compte _...  message,erreur,validation,compter,imputer,cent...\n",
              "19  Message d'erreur \"Le fournisseur MDM___ n’exis...               message,erreur,fournisseur,coexister"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3whVJKgSzlI"
      },
      "source": [
        "# **Test Example2**\n",
        "---\n",
        "`BDD: df_new`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "-L1ySClCJeUQ",
        "outputId": "7a3e4dfd-cfa5-42d9-899c-f20a0bcb4734"
      },
      "source": [
        "sentence = 'Message d\\'erreur \\\"La qte livree est differente de la qte facturee ; fonction impossible\"'\n",
        "sentence = 'message d\\'erreur'\n",
        "sentence = \"groupe d'acheteurs non défini\"\n",
        "sentence = \"UO4\"\n",
        "sentence = 'erreur de conversion'\n",
        "sentence = \"le fournisseur MDM n'existe pas\"\n",
        "init(df_new) \n",
        "\n",
        "cosine_similarity_T(10,sentence,df_new )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init!!!\n",
            "\n",
            "------------pre_process--------\n",
            "\n",
            "\n",
            "sentence to words :  ['fournisseur', 'mdm', 'existe', 'pas']\n",
            "['fournisseur', 'mdm', 'existe', 'pas']\n",
            "\n",
            "------------correction--------\n",
            "\n",
            "['fournisseur', 'mdm', 'existe', 'pas']\n",
            "\n",
            "------------stemming--------\n",
            "\n",
            "['fournisseur', 'mdm', 'exister', 'pas']\n",
            "\n",
            "------------remove stop-words--------\n",
            "\n",
            "['fournisseur', 'mdm', 'exister']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "---q_df\n",
            "                   q_clean\n",
            "0  fournisseur,mdm,exister\n",
            "\n",
            "\n",
            "\n",
            "fournisseur : 56\n",
            "mdm : 104\n",
            "exister : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>Message d'erreur \"Le fournisseur MDM___ n’exis...</td>\n",
              "      <td>0.781490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Message d'erreur : \"Le fournisseur ARIBA n'exi...</td>\n",
              "      <td>0.600296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>Message d'erreur \"Le fournisseur MDM___ est bl...</td>\n",
              "      <td>0.587467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>Message d'erreur \"Le centre de profit __ n'exi...</td>\n",
              "      <td>0.236420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>Message d'erreur \"Il existe des factures pour ...</td>\n",
              "      <td>0.214371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>53</td>\n",
              "      <td>Message d'erreur \"Fournisseur non present dans...</td>\n",
              "      <td>0.142208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18</td>\n",
              "      <td>Message d'erreur \"Validation ___ : le compte _...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>30</td>\n",
              "      <td>Message d'erreur \"Renseigner correctement le d...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>29</td>\n",
              "      <td>Message d'erreur \"Article ___ non gere dans la...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>28</td>\n",
              "      <td>Message d'erreur \"Fonctions oblig. Suivantes n...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  index                                            Subject     Score\n",
              "0    19  Message d'erreur \"Le fournisseur MDM___ n’exis...  0.781490\n",
              "1     0  Message d'erreur : \"Le fournisseur ARIBA n'exi...  0.600296\n",
              "2    20  Message d'erreur \"Le fournisseur MDM___ est bl...  0.587467\n",
              "3    14  Message d'erreur \"Le centre de profit __ n'exi...  0.236420\n",
              "4    33  Message d'erreur \"Il existe des factures pour ...  0.214371\n",
              "5    53  Message d'erreur \"Fournisseur non present dans...  0.142208\n",
              "6    18  Message d'erreur \"Validation ___ : le compte _...  0.000000\n",
              "7    30  Message d'erreur \"Renseigner correctement le d...  0.000000\n",
              "8    29  Message d'erreur \"Article ___ non gere dans la...  0.000000\n",
              "9    28  Message d'erreur \"Fonctions oblig. Suivantes n...  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw06nA5I2jH0"
      },
      "source": [
        "# **3:non-utilisé: Créer les keywords à partir d'une phrase en se basant sur les mots d'un dictionnaire en passant par la tokenization et le removeStopWords**\n",
        "---\n",
        "`BDD: df_news`\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUmB7tvXmi9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b69780b-b905-408d-ba71-8d0abdedb3e9"
      },
      "source": [
        "#https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb\n",
        "import re\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "with open('stp_words_.txt','r') as f:\n",
        "    Stop_words_strong = f.read()\n",
        "\n",
        "\n",
        "\n",
        "Stop_words_strong = re.findall(r'\\w+',Stop_words_strong)\n",
        "Stop_words_strong.append(\"quelqu\")\n",
        "docs ='''Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment Trouvé apparemment *t sur le parapet de ce mur que s'ouvraient les ailes de la jeunesse. Douce et sainte illusion de l'espoir de la vaincre. Assez avisé pour juger tout effet inutile dans ce cabinet où l'air est si doux, vous ne faites jamais rien sans raison, que c'en était fait du mal. Accoutumé à vivre du présent, nous savons depuis deuxabinet où l'air est si doux, vous ne faites jamais rien sans raison, que c'en était fait du mal. Accoutumé à vivre du présent, nous savons depuis deuxabinet où l'air est si doux, vous ne faites jamais rien sans raison, que c'en était fait du mal. Accoutumé à vivre du présent, nous savons depuis deux jours. Comprenant tout à coup renaissante animait d'une sève nouvelle, sans qu'aucune des précédentes. Abandonnez votre jeu et asseyez-vous à côté de l'avenir de notre entreprise. Planter là, et il reconnut bientôt que c'était impossible de bouger ou de parler. Allez-vous-en, et soyez comme une petite désespérée vers la mule. parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet parapet'''\n",
        "\n",
        "sentence = re.sub('[?,.]','',docs)\n",
        "listes_phrases = sentence.split(' ')\n",
        "cv = CountVectorizer(max_df=0.85,stop_words=Stop_words_strong,max_features=10000)\n",
        "\n",
        "\n",
        "word_count_vector = cv.fit_transform(listes_phrases)\n",
        "\n",
        "#Now, let's look at 10 words from our vocabulary. Sweet, these are mostly programming related.\n",
        "liste = list(cv.vocabulary_.keys())[:]\n",
        "\n",
        "#>>> liste\n",
        "#['trouvé', 'apparemment', 'parapet', 'mur', 'ouvraient', 'ailes', 'jeunesse', 'douce', 'sainte', 'illusion', 'espoir', 'vaincre', 'avisé', 'juger', 'inutile', 'cabinet', 'air', 'doux', 'jamais', 'raison', 'mal', 'accoutumé', 'vivre', 'présent', 'savons', 'jours', 'comprenant', 'coup', 'renaissante', 'animait', 'sève','nouvelle', 'précédentes', 'abandonnez', 'jeu', 'asseyez', 'côté', 'avenir', 'entreprise', 'planter', 'reconnut', 'bientôt', 'impossible', 'bouger', 'parler', 'allez', 'petite', 'désespérée', 'mule']\n",
        "\n",
        "#We can also get the vocabulary by using get_feature_names()\n",
        "liste2 = list(cv.get_feature_names())[2000:2015]\n",
        "\n",
        "# you only needs to do this once\n",
        "feature_names=cv.get_feature_names()\n",
        "print('keywords')\n",
        "feature_names[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keywords\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abandonnez',\n",
              " 'accoutumé',\n",
              " 'ailes',\n",
              " 'air',\n",
              " 'allez',\n",
              " 'animait',\n",
              " 'apparemment',\n",
              " 'asseyez',\n",
              " 'avenir',\n",
              " 'avisé']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "DYXdFWajWtX7",
        "outputId": "0c00687d-ba6a-4c9e-eab4-a1a9669ee570"
      },
      "source": [
        "df_new.loc[40:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Clean_Keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Message d'erreur \" Enregistrer uniq. ds les pe...</td>\n",
              "      <td>message,erreur,enregistrer,uniq,periode,possib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Message d'erreur \" Periode ___ n’est pas ouver...</td>\n",
              "      <td>message,erreur,periode,n’est,ouvrir,typer,dpte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Message d'erreur \" Le document ne contient auc...</td>\n",
              "      <td>message,erreur,document,contenir,poster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Message d'erreur \"Aucune entree en stock possi...</td>\n",
              "      <td>message,erreur,entrer,stock,possible,commander</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Message d'erreur \"Entree marchandises – comman...</td>\n",
              "      <td>message,erreur,entrer,marchandise,commander,au...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Message d'erreur \"Le centre ___ est bloque aux...</td>\n",
              "      <td>message,erreur,centrer,bloquer,ecriture,cout,p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Message d'erreur \"Statut utilisateur ZBHA acti...</td>\n",
              "      <td>message,erreur,statut,utilisateur,zbha,actif,otp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Message d'erreur \"Statut systeme BLOQ actif (O...</td>\n",
              "      <td>message,erreur,statut,systeme,bloq,actif,otp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Message d'erreur \"Statut utilisateur FERM acti...</td>\n",
              "      <td>message,erreur,statut,utilisateur,ferm,actif,otp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Message d'erreur \"Ecritures d’immobilisations ...</td>\n",
              "      <td>message,erreur,ecriture,d’immobilisations,ste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Message d'erreur \"Les donnees de division de l...</td>\n",
              "      <td>message,erreur,donnee,division,article,bloquer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Message d'erreur \"Utilisateur YRARIBATCH trait...</td>\n",
              "      <td>message,erreur,utilisateur,yraribatch,traiter,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Message d'erreur \"Tableau 01: La valeur d'acqu...</td>\n",
              "      <td>message,erreur,tableau,acquisition,devier,negatif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Message d'erreur \"Fournisseur non present dans...</td>\n",
              "      <td>message,erreur,fournisseur,present,dan,ariba,p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Message d'erreur \"Vendeur a ete supprime(e) (m...</td>\n",
              "      <td>message,erreur,vendeur,supprimer,modification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Message d'erreur \"La PR reste au statut « Appr...</td>\n",
              "      <td>message,erreur,rester,statut,approuver,n’y,com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>ppp</td>\n",
              "      <td>ppp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>UO4-5 Commande | Envoi d'une commande manuelle</td>\n",
              "      <td>uo4,commander,envoi,commander,manuel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>UO5-4 Reception | Anomalie workflow</td>\n",
              "      <td>uo5,reception,anomalie,workflow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>UO5-1 Reception | Modification(s) de reception(s)</td>\n",
              "      <td>uo5,reception,modification,reception</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>UO5-2 Reception | Annulation(s) de reception(s)</td>\n",
              "      <td>uo5,reception,annulation,reception</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>UO5-3 Reception | Forcer la reception</td>\n",
              "      <td>uo5,reception,forcer,reception</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>UO3-5 Demande d'achat | Demande de support cre...</td>\n",
              "      <td>uo3,demander,achat,demander,support,creation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>UO3-6 Demande d'achat | Demande de support mod...</td>\n",
              "      <td>uo3,demander,achat,demander,support,modification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>UO3-7 Demande d'achat | Demande de support ann...</td>\n",
              "      <td>uo3,demander,achat,demander,support,annulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>UO4-2 Commande | Demande de support modificati...</td>\n",
              "      <td>uo4,commander,demander,support,modification,co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Subject                                      Clean_Keyword\n",
              "40  Message d'erreur \" Enregistrer uniq. ds les pe...  message,erreur,enregistrer,uniq,periode,possib...\n",
              "41  Message d'erreur \" Periode ___ n’est pas ouver...     message,erreur,periode,n’est,ouvrir,typer,dpte\n",
              "42  Message d'erreur \" Le document ne contient auc...            message,erreur,document,contenir,poster\n",
              "43  Message d'erreur \"Aucune entree en stock possi...     message,erreur,entrer,stock,possible,commander\n",
              "44  Message d'erreur \"Entree marchandises – comman...  message,erreur,entrer,marchandise,commander,au...\n",
              "45  Message d'erreur \"Le centre ___ est bloque aux...  message,erreur,centrer,bloquer,ecriture,cout,p...\n",
              "46  Message d'erreur \"Statut utilisateur ZBHA acti...   message,erreur,statut,utilisateur,zbha,actif,otp\n",
              "47  Message d'erreur \"Statut systeme BLOQ actif (O...       message,erreur,statut,systeme,bloq,actif,otp\n",
              "48  Message d'erreur \"Statut utilisateur FERM acti...   message,erreur,statut,utilisateur,ferm,actif,otp\n",
              "49  Message d'erreur \"Ecritures d’immobilisations ...      message,erreur,ecriture,d’immobilisations,ste\n",
              "50  Message d'erreur \"Les donnees de division de l...  message,erreur,donnee,division,article,bloquer...\n",
              "51  Message d'erreur \"Utilisateur YRARIBATCH trait...  message,erreur,utilisateur,yraribatch,traiter,...\n",
              "52  Message d'erreur \"Tableau 01: La valeur d'acqu...  message,erreur,tableau,acquisition,devier,negatif\n",
              "53  Message d'erreur \"Fournisseur non present dans...  message,erreur,fournisseur,present,dan,ariba,p...\n",
              "54  Message d'erreur \"Vendeur a ete supprime(e) (m...      message,erreur,vendeur,supprimer,modification\n",
              "55  Message d'erreur \"La PR reste au statut « Appr...  message,erreur,rester,statut,approuver,n’y,com...\n",
              "56                                                ppp                                                ppp\n",
              "57     UO4-5 Commande | Envoi d'une commande manuelle               uo4,commander,envoi,commander,manuel\n",
              "58                UO5-4 Reception | Anomalie workflow                    uo5,reception,anomalie,workflow\n",
              "59  UO5-1 Reception | Modification(s) de reception(s)               uo5,reception,modification,reception\n",
              "60    UO5-2 Reception | Annulation(s) de reception(s)                 uo5,reception,annulation,reception\n",
              "61              UO5-3 Reception | Forcer la reception                     uo5,reception,forcer,reception\n",
              "62  UO3-5 Demande d'achat | Demande de support cre...       uo3,demander,achat,demander,support,creation\n",
              "63  UO3-6 Demande d'achat | Demande de support mod...   uo3,demander,achat,demander,support,modification\n",
              "64  UO3-7 Demande d'achat | Demande de support ann...     uo3,demander,achat,demander,support,annulation\n",
              "65  UO4-2 Commande | Demande de support modificati...  uo4,commander,demander,support,modification,co..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}